{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00099933-b57a-4798-aad8-574c71215b7b",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7e01932e-7087-4660-b619-c329c5b33b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.py\n",
    "# General\n",
    "import os\n",
    "\n",
    "# LangChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "GEMINI_MODEL=\"gemini-2.5-flash\"\n",
    "GEMINI_API_KEY=\"AIzaSyDHtORZwqG3IrdWGtOq7GMZRta7F7SK9SU\"\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
    "\n",
    "def create_model():\n",
    "    return ChatGoogleGenerativeAI(\n",
    "        model=GEMINI_MODEL,\n",
    "        max_retries=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a045c-6036-49fb-af4e-af658735d3fa",
   "metadata": {},
   "source": [
    "# Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d316fb10-0e62-4309-9b2d-031f1dec07d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting session.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile session.py\n",
    "# General\n",
    "from dataclasses import dataclass\n",
    "    \n",
    "class TopologicSession:\n",
    "    def __init__(self):\n",
    "        self.items = {}\n",
    "\n",
    "    def add(self, name, obj):\n",
    "        self.items[name] = obj\n",
    "        return f\"Object '{name}' saved.\"\n",
    "\n",
    "    def get_all_names(self):\n",
    "        return list(self.items.keys())\n",
    "        \n",
    "@dataclass\n",
    "class SessionContext:\n",
    "    session: TopologicSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5144428e-c09c-48ab-b3ae-ddecfdbe2e44",
   "metadata": {},
   "source": [
    "# Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a0b18500-0ae4-4204-af7c-c96533bcea65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting common.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile common.py\n",
    "# Topologic\n",
    "from topologicpy.Topology import Topology\n",
    "from topologicpy.Dictionary import Dictionary\n",
    "\n",
    "def assign_name(obj, name: str):\n",
    "    keys = [\"name\"]\n",
    "    values = [name]\n",
    "    config = Dictionary.ByKeysValues(keys, values)\n",
    "    obj = Topology.SetDictionary(obj, config)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c8545-0873-44c4-9ddb-ac7bbab377af",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cd7fd47e-5a50-46ae-b1e3-3446d2455454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tools.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tools.py\n",
    "from typing import List, Optional\n",
    "import uuid\n",
    "\n",
    "# General\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Local libraries\n",
    "from common import assign_name\n",
    "from session import SessionContext\n",
    "\n",
    "# LangChain\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "# Topologic\n",
    "from topologicpy.Vertex import Vertex\n",
    "from topologicpy.Topology import Topology\n",
    "from topologicpy.Cell import Cell\n",
    "\n",
    "@tool\n",
    "def create_vertexes(\n",
    "    runtime: ToolRuntime[SessionContext],\n",
    "    coordinates: List[List[float]],\n",
    "):\n",
    "    \"\"\"Creates a list of vertexes in the 3D plane and show them.\n",
    "    Args:\n",
    "        coordinates: A list of lists, where each list contains [x, y, z] coordinates.\n",
    "                     Example: [[0, 0, 0], [10, 5, 0]]\n",
    "    \"\"\"\n",
    "    vertexesCount = 0\n",
    "\n",
    "    for coordinate in coordinates:\n",
    "        name = f\"vertex {uuid.uuid4()}\"\n",
    "        vertex = Vertex.ByCoordinates(*coordinate)\n",
    "        vertex = assign_name(vertex, name)\n",
    "        runtime.context.session.add(name, vertex)\n",
    "        vertexesCount += 1\n",
    "\n",
    "    return f\"{vertexesCount} vertexes were created and registered\"\n",
    "\n",
    "@tool\n",
    "def create_cube(\n",
    "    runtime: ToolRuntime[SessionContext],\n",
    "    size: int,\n",
    "    origin: Optional[list[float]],\n",
    "    name: Optional[str] = None\n",
    "):\n",
    "    \"\"\"Creates a cube given an optional name and a size.\n",
    "    Args:\n",
    "        size: size of the cube.\n",
    "        origin (optional): origin of the cube that contains [x, y, z] coordinates.\n",
    "        name (optional): custom name of the cube.\n",
    "    \"\"\"\n",
    "    if origin == None:\n",
    "        origin = [0, 0, 0]\n",
    "    if name == None:\n",
    "        name = f\"cube {uuid.uuid4()}\"\n",
    "    \n",
    "    origin = (origin[0], origin[1], origin[2])\n",
    "    cube = Cell.Cube(origin=origin, size=size)\n",
    "    cube = assign_name(cube, name)\n",
    "    runtime.context.session.add(name, cube)\n",
    "    \n",
    "    return f\"A cube with name {name} has been created and registered\"\n",
    "\n",
    "@tool\n",
    "def clear_session(\n",
    "    runtime: ToolRuntime[SessionContext],\n",
    "):\n",
    "    \"\"\"Delete/Clear all objects from current session.\"\"\"\n",
    "    runtime.context.session.items = {}\n",
    "    return f\"The session has been deleted\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f6fd2-e3fc-424b-bdf2-922f64c98d89",
   "metadata": {},
   "source": [
    "# App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7301cccd-5f99-4a4d-aa65-cd16c92874f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "# General\n",
    "import plotly.graph_objects as go\n",
    "import streamlit as st\n",
    "\n",
    "# Local libraries\n",
    "from config import create_model\n",
    "from session import TopologicSession, SessionContext\n",
    "from tools import create_vertexes, create_cube, clear_session\n",
    "\n",
    "# AI\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# Topologic\n",
    "from topologicpy.Cluster import Cluster\n",
    "from topologicpy.Plotly import Plotly\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(\"Topologic Vibe\")\n",
    "col_chat, col_viz = st.columns([1, 2])\n",
    "\n",
    "# Agent\n",
    "agent = create_agent(\n",
    "    model=create_model(),\n",
    "    tools=[\n",
    "        clear_session,\n",
    "        create_cube, create_vertexes\n",
    "    ],\n",
    "    context_schema=SessionContext,\n",
    "    system_prompt=\"You are a topologicpy library assistant.\"\n",
    ")\n",
    "\n",
    "# Session\n",
    "if \"topologic_session\" not in st.session_state:\n",
    "    st.session_state.topologic_session = TopologicSession()\n",
    "\n",
    "session = st.session_state.topologic_session\n",
    "session_context = SessionContext(session=session)\n",
    "\n",
    "# --- ASSISTANT MESSAGES ---\n",
    "with col_chat:\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "\n",
    "    # Show history\n",
    "    for msg in st.session_state.messages:\n",
    "        with st.chat_message(msg[\"role\"]):\n",
    "            st.markdown(msg[\"content\"])\n",
    "\n",
    "    # User input\n",
    "    if prompt := st.chat_input(\"What do you want to build?\"):\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(prompt)\n",
    "\n",
    "        # Invoke model\n",
    "        for chunk in agent.stream(\n",
    "            {\"messages\": prompt},\n",
    "            context=session_context,\n",
    "            stream_mode=\"updates\",\n",
    "        ):\n",
    "            for step, data in chunk.items():\n",
    "                step = step\n",
    "                content = data['messages'][-1].content_blocks\n",
    "\n",
    "                if step == \"model\":\n",
    "                    if content[0][\"type\"] == \"tool_call\":\n",
    "                        response = f\"Calling to {content[0]['name']} function.\"\n",
    "                    else:\n",
    "                        response = content[0][\"text\"]\n",
    "                \n",
    "                    with st.chat_message(\"assistant\"):\n",
    "                        st.markdown(response)\n",
    "                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "# --- TOPOLOGIC OUTPUT ---\n",
    "with col_viz:\n",
    "    # Collecting object and transforming into a single topology\n",
    "    objs = []\n",
    "    for name, obj in session_context.session.items.items():\n",
    "        objs.append(obj)\n",
    "\n",
    "    scene = Cluster.ByTopologies(objs)\n",
    "    data = Plotly.DataByTopology(scene)\n",
    "    fig = go.Figure(data=data)\n",
    "    \n",
    "    # Show in streamlit\n",
    "    st.plotly_chart(fig, theme=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2eb16253-8d03-4205-89fe-f760b9332f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import plotly.graph_objects as go\n",
    "import streamlit as st\n",
    "\n",
    "# Local libraries\n",
    "from config import create_model\n",
    "from session import TopologicSession, SessionContext\n",
    "from tools import create_vertexes, create_cube, clear_session\n",
    "\n",
    "# AI\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# Topologic\n",
    "from topologicpy.Cluster import Cluster\n",
    "from topologicpy.Plotly import Plotly\n",
    "\n",
    "# 1. Page Config & Custom CSS for a \"Fixed\" feel\n",
    "st.set_page_config(layout=\"wide\", page_title=\"Topologic Vibe\")\n",
    "\n",
    "# UI Styling: Remove extra padding to maximize space\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "        .block-container { padding-top: 2rem; padding-bottom: 0rem; }\n",
    "        .stChatFloatingInputContainer { bottom: 20px; }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "st.title(\"Topologic Vibe\")\n",
    "\n",
    "# 2. Agent Setup (Unchanged)\n",
    "agent = create_agent(\n",
    "    model=create_model(),\n",
    "    tools=[clear_session, create_cube, create_vertexes],\n",
    "    context_schema=SessionContext,\n",
    "    system_prompt=\"You are a topologicpy library assistant.\"\n",
    ")\n",
    "\n",
    "if \"topologic_session\" not in st.session_state:\n",
    "    st.session_state.topologic_session = TopologicSession()\n",
    "\n",
    "session = st.session_state.topologic_session\n",
    "session_context = SessionContext(session=session)\n",
    "\n",
    "# 3. Layout: Define columns\n",
    "col_chat, col_viz = st.columns([1, 2], gap=\"medium\")\n",
    "\n",
    "# --- ASSISTANT MESSAGES ---\n",
    "with col_chat:\n",
    "    # Create a scrollable container for messages with a fixed height\n",
    "    # This keeps the chat history contained and the input at the bottom\n",
    "    chat_container = st.container(height=650) \n",
    "\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "\n",
    "    # Show history inside the scrollable container\n",
    "    with chat_container:\n",
    "        for msg in st.session_state.messages:\n",
    "            with st.chat_message(msg[\"role\"]):\n",
    "                st.markdown(msg[\"content\"])\n",
    "\n",
    "    # User input (Standard chat_input sits at the bottom of its parent container)\n",
    "    if prompt := st.chat_input(\"What do you want to build?\"):\n",
    "        # Add user message to state and UI\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        with chat_container:\n",
    "            with st.chat_message(\"user\"):\n",
    "                st.markdown(prompt)\n",
    "\n",
    "        # Invoke model\n",
    "        for chunk in agent.stream(\n",
    "            {\"messages\": prompt},\n",
    "            context=session_context,\n",
    "            stream_mode=\"updates\",\n",
    "        ):\n",
    "            for step, data in chunk.items():\n",
    "                content = data['messages'][-1].content_blocks\n",
    "\n",
    "                if step == \"model\":\n",
    "                    if content[0][\"type\"] == \"tool_call\":\n",
    "                        response = f\"Calling to {content[0]['name']} function.\"\n",
    "                    else:\n",
    "                        response = content[0][\"text\"]\n",
    "                    \n",
    "                    # Display assistant response in the scrollable container\n",
    "                    with chat_container:\n",
    "                        with st.chat_message(\"assistant\"):\n",
    "                            st.markdown(response)\n",
    "                    \n",
    "                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        \n",
    "        # Rerun to refresh the visualization on the right after tool calls\n",
    "        st.rerun()\n",
    "\n",
    "# --- TOPOLOGIC OUTPUT ---\n",
    "with col_viz:\n",
    "    objs = [obj for name, obj in session_context.session.items.items()]\n",
    "    \n",
    "    if objs:\n",
    "        scene = Cluster.ByTopologies(objs)\n",
    "        data = Plotly.DataByTopology(scene)\n",
    "        fig = go.Figure(data=data)\n",
    "        \n",
    "        # 4. Fix Vertex Appearance & Plot Size\n",
    "        # Iterating through traces to find scatter points (vertexes)\n",
    "        for trace in fig.data:\n",
    "            # Check if trace has markers (vertices)\n",
    "            if hasattr(trace, 'marker'):\n",
    "                trace.marker.size = 8          # Increase size\n",
    "                trace.marker.color = 'white'   # Set color to white\n",
    "                trace.marker.line = dict(width=1, color='black') # Contrast border\n",
    "\n",
    "        # 5. Fix Plot Height and Margins\n",
    "        fig.update_layout(\n",
    "            height=750, # Set explicit height\n",
    "            margin=dict(l=0, r=0, b=0, t=0), # Remove wasted space\n",
    "            scene=dict(\n",
    "                xaxis=dict(gridcolor='gray'),\n",
    "                yaxis=dict(gridcolor='gray'),\n",
    "                zaxis=dict(gridcolor='gray'),\n",
    "                bgcolor='rgba(0,0,0,0)' # Transparent background\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        st.plotly_chart(fig, width=\"stretch\", theme=None)\n",
    "    else:\n",
    "        st.info(\"The canvas is empty. Tell the assistant to create something!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8cc20-87ad-4d5e-abf1-d2792525c538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ec4af-bbf0-497f-b34c-fac1ba4a9b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
